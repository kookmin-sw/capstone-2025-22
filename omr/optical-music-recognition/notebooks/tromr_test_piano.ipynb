{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xml -> annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH=f\"../data\"\n",
    "MODEL_PATH=f\"../model\"\n",
    "IMAGE_PATH=f\"../images/\"\n",
    "\n",
    "DATA_FEATURE_PATH=f\"{DATA_PATH}/processed-feature\"\n",
    "DATA_RAW_PATH=f\"{DATA_PATH}/raw\"\n",
    "DATA_TEST_PATH=f\"{DATA_PATH}/test\"\n",
    "\n",
    "PrIMuS=\"PrIMuS\"\n",
    "package_aa = \"package_aa_short\"\n",
    "\n",
    "\n",
    "xml_path = f'{DATA_RAW_PATH}/{PrIMuS}/Rock-ver/Rock-ver.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from timm.models.vision_transformer import VisionTransformer\n",
    "from timm.models.vision_transformer_hybrid import HybridEmbed\n",
    "from timm.models.resnetv2 import ResNetV2\n",
    "from timm.models.layers import StdConv2dSame\n",
    "from einops import repeat\n",
    "\n",
    "class CustomVisionTransformer(VisionTransformer):\n",
    "    def __init__(self, img_size, patch_size=16, *args, **kwargs):\n",
    "        super(CustomVisionTransformer, self).__init__(img_size=img_size, patch_size=patch_size, *args, **kwargs)\n",
    "        self.height, self.width = img_size\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        B, c, h, w = x.shape\n",
    "        x = self.patch_embed(x)\n",
    "\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1) \n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        h, w = h//self.patch_size, w//self.patch_size\n",
    "        pos_emb_ind = repeat(torch.arange(h)*(self.width//self.patch_size-w), 'h -> (h w)', w=w)+torch.arange(h*w)\n",
    "        pos_emb_ind = torch.cat((torch.zeros(1), pos_emb_ind+1), dim=0).long()\n",
    "        x += self.pos_embed[:, pos_emb_ind]\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "def get_encoder(args):\n",
    "    backbone_layers = list(args.backbone_layers)\n",
    "    backbone = ResNetV2(\n",
    "        layers=backbone_layers, num_classes=0, global_pool='', in_chans=args.channels,\n",
    "        preact=False, stem_type='same', conv_layer=StdConv2dSame)\n",
    "    min_patch_size = 2**(len(backbone_layers)+1)\n",
    "\n",
    "    def embed_layer(**x):\n",
    "        ps = x.pop('patch_size', min_patch_size)\n",
    "        assert ps % min_patch_size == 0 and ps >= min_patch_size, 'patch_size needs to be multiple of %i with current backbone configuration' % min_patch_size\n",
    "        return HybridEmbed(**x, patch_size=ps//min_patch_size, backbone=backbone)\n",
    "\n",
    "    encoder = CustomVisionTransformer(img_size=(args.max_height, args.max_width),\n",
    "                                      patch_size=args.patch_size,\n",
    "                                      in_chans=args.channels,\n",
    "                                      num_classes=0,\n",
    "                                      embed_dim=args.encoder_dim,\n",
    "                                      depth=args.encoder_depth,\n",
    "                                      num_heads=args.encoder_heads,\n",
    "                                      embed_layer=embed_layer,\n",
    "                                      global_pool=\"\"\n",
    "                                      )\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from x_transformers.x_transformers import AttentionLayers, TokenEmbedding, AbsolutePositionalEmbedding, Decoder\n",
    "\n",
    "class ScoreTransformerWrapper(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_note_tokens,\n",
    "        num_rhythm_tokens,\n",
    "        num_pitch_tokens,\n",
    "        num_lift_tokens,\n",
    "        max_seq_len,\n",
    "        attn_layers,\n",
    "        emb_dim,\n",
    "        l2norm_embed = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert isinstance(attn_layers, AttentionLayers), 'attention layers must be one of Encoder or Decoder'\n",
    "\n",
    "        dim = attn_layers.dim\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.l2norm_embed = l2norm_embed\n",
    "        self.lift_emb = TokenEmbedding(emb_dim, num_lift_tokens, l2norm_embed = l2norm_embed)\n",
    "        self.pitch_emb = TokenEmbedding(emb_dim, num_pitch_tokens, l2norm_embed = l2norm_embed)\n",
    "        self.rhythm_emb = TokenEmbedding(emb_dim, num_rhythm_tokens, l2norm_embed = l2norm_embed)\n",
    "        self.pos_emb = AbsolutePositionalEmbedding(emb_dim, max_seq_len, l2norm_embed = l2norm_embed)\n",
    "\n",
    "        self.project_emb = nn.Linear(emb_dim, dim) if emb_dim != dim else nn.Identity()\n",
    "        self.attn_layers = attn_layers\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.init_()\n",
    "\n",
    "        self.to_logits_lift = nn.Linear(dim, num_lift_tokens)\n",
    "        self.to_logits_pitch = nn.Linear(dim, num_pitch_tokens)\n",
    "        self.to_logits_rhythm = nn.Linear(dim, num_rhythm_tokens)\n",
    "        self.to_logits_note = nn.Linear(dim, num_note_tokens)\n",
    "\n",
    "    def init_(self):\n",
    "        if self.l2norm_embed:\n",
    "            nn.init.normal_(self.lift_emb.emb.weight, std = 1e-5)\n",
    "            nn.init.normal_(self.pitch_emb.emb.weight, std = 1e-5)\n",
    "            nn.init.normal_(self.rhythm_emb.emb.weight, std = 1e-5)\n",
    "            nn.init.normal_(self.pos_emb.emb.weight, std = 1e-5)\n",
    "            return\n",
    "\n",
    "        nn.init.kaiming_normal_(self.lift_emb.emb.weight)\n",
    "        nn.init.kaiming_normal_(self.pitch_emb.emb.weight)\n",
    "        nn.init.kaiming_normal_(self.rhythm_emb.emb.weight)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        rhythms,\n",
    "        pitchs,\n",
    "        lifts,\n",
    "        mask = None,\n",
    "        return_hiddens = True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        x = self.rhythm_emb(rhythms) + self.pitch_emb(pitchs) + self.lift_emb(lifts) + self.pos_emb(rhythms)\n",
    "        x = self.project_emb(x)\n",
    "        x, hiddens = self.attn_layers(x, mask = mask, return_hiddens = return_hiddens, **kwargs)\n",
    "        # select_hiddens = hiddens[0][3]\n",
    "        \n",
    "        x = self.norm(x)\n",
    "\n",
    "        out_lifts = self.to_logits_lift(x)\n",
    "        out_pitchs = self.to_logits_pitch(x)\n",
    "        out_rhythms = self.to_logits_rhythm(x)\n",
    "        out_notes = self.to_logits_note(x)\n",
    "        return out_rhythms, out_pitchs, out_lifts, out_notes, x\n",
    "\n",
    "def top_k(logits, thres = 0.9):\n",
    "    k = ceil((1 - thres) * logits.shape[-1])\n",
    "    val, ind = torch.topk(logits, k)\n",
    "    probs = torch.full_like(logits, float('-inf'))\n",
    "    probs.scatter_(1, ind, val)\n",
    "    return probs\n",
    "\n",
    "class ScoreDecoder(nn.Module):\n",
    "    def __init__(self, transoformer, noteindexes, num_rhythmtoken, ignore_index = -100, pad_value = 0):\n",
    "        super().__init__()\n",
    "        self.pad_value = pad_value\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "        self.net = transoformer\n",
    "        self.max_seq_len = transoformer.max_seq_len\n",
    "\n",
    "        note_mask = torch.zeros(num_rhythmtoken)\n",
    "        note_mask[noteindexes] = 1\n",
    "        self.note_mask = nn.Parameter(note_mask)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, start_tokens, nonote_tokens, seq_len, eos_token = None, temperature = 1., filter_thres = 0.9, min_p_pow=2.0, min_p_ratio=0.02, **kwargs):\n",
    "        device = start_tokens.device\n",
    "        was_training = self.net.training\n",
    "        num_dims = len(start_tokens.shape)\n",
    "\n",
    "        if num_dims == 1:\n",
    "            start_tokens = start_tokens[None, :]\n",
    "\n",
    "        b, t = start_tokens.shape\n",
    "\n",
    "        self.net.eval()\n",
    "        out_rhythm = start_tokens\n",
    "        out_pitch = nonote_tokens\n",
    "        out_lift = nonote_tokens\n",
    "        mask = kwargs.pop('mask', None)\n",
    "\n",
    "        if mask is None:\n",
    "            mask = torch.full_like(out_rhythm, True, dtype=torch.bool, device=out_rhythm.device)\n",
    "\n",
    "        for _ in range(seq_len):\n",
    "            mask = mask[:, -self.max_seq_len:]\n",
    "            x_lift = out_lift[:, -self.max_seq_len:]\n",
    "            x_pitch = out_pitch[:, -self.max_seq_len:]\n",
    "            x_rhymthm = out_rhythm[:, -self.max_seq_len:]\n",
    "            \n",
    "            rhythmsp, pitchsp, liftsp, notesp, _ = self.net(x_rhymthm, x_pitch, x_lift,  mask=mask, **kwargs)\n",
    "            \n",
    "            filtered_lift_logits = top_k(liftsp[:, -1, :], thres = filter_thres)\n",
    "            filtered_pitch_logits = top_k(pitchsp[:, -1, :], thres = filter_thres)\n",
    "            filtered_rhythm_logits = top_k(rhythmsp[:, -1, :], thres = filter_thres)\n",
    "\n",
    "            lift_probs = F.softmax(filtered_lift_logits / temperature, dim=-1)\n",
    "            pitch_probs = F.softmax(filtered_pitch_logits / temperature, dim=-1)\n",
    "            rhythm_probs = F.softmax(filtered_rhythm_logits / temperature, dim=-1)\n",
    "            \n",
    "            lift_sample = torch.multinomial(lift_probs, 1)\n",
    "            pitch_sample = torch.multinomial(pitch_probs, 1)\n",
    "            rhythm_sample = torch.multinomial(rhythm_probs, 1)\n",
    "\n",
    "            out_lift = torch.cat((out_lift, lift_sample), dim=-1)\n",
    "            out_pitch = torch.cat((out_pitch, pitch_sample), dim=-1)\n",
    "            out_rhythm = torch.cat((out_rhythm, rhythm_sample), dim=-1)\n",
    "            mask = F.pad(mask, (0, 1), value=True)\n",
    "\n",
    "            if eos_token is not None and (torch.cumsum(out_rhythm == eos_token, 1)[:, -1] >= 1).all():\n",
    "                break\n",
    "\n",
    "        out_lift = out_lift[:, t:]\n",
    "        out_pitch = out_pitch[:, t:]\n",
    "        out_rhythm = out_rhythm[:, t:]\n",
    "\n",
    "        if num_dims == 1:\n",
    "            out = out.squeeze(0)\n",
    "\n",
    "        self.net.train(was_training)\n",
    "        return out_rhythm, out_pitch, out_lift\n",
    "\n",
    "    def forward(self, rhythms, pitchs, lifts,notes, **kwargs):\n",
    "        liftsi = lifts[:, :-1]\n",
    "        liftso = lifts[:, 1:]\n",
    "        pitchsi = pitchs[:, :-1]\n",
    "        pitchso = pitchs[:, 1:]\n",
    "        rhythmsi = rhythms[:, :-1]\n",
    "        rhythmso = rhythms[:, 1:]\n",
    "        noteso = notes[:, 1:]\n",
    "\n",
    "        mask = kwargs.get('mask', None)\n",
    "        if mask is not None and mask.shape[1] == rhythms.shape[1]:\n",
    "            mask = mask[:, :-1]\n",
    "            kwargs['mask'] = mask\n",
    "\n",
    "        rhythmsp, pitchsp, liftsp, notesp, x = self.net(rhythmsi, pitchsi, liftsi, **kwargs) \n",
    "        \n",
    "        loss_consist = self.calConsistencyLoss(rhythmsp, pitchsp, liftsp,notesp)\n",
    "        loss_rhythm = F.cross_entropy(rhythmsp.transpose(1, 2), rhythmso, ignore_index = self.ignore_index)\n",
    "        loss_pitch = F.cross_entropy(pitchsp.transpose(1, 2), pitchso, ignore_index = self.ignore_index)\n",
    "        loss_lift = F.cross_entropy(liftsp.transpose(1, 2), liftso, ignore_index = self.ignore_index)\n",
    "        loss_note = F.cross_entropy(notesp.transpose(1, 2), noteso, ignore_index = self.ignore_index)\n",
    "        \n",
    "        return dict(\n",
    "            loss_rhythm=loss_rhythm,\n",
    "            loss_pitch=loss_pitch,\n",
    "            loss_lift=loss_lift,\n",
    "            loss_consist=loss_consist,\n",
    "            loss_note = loss_note\n",
    "        )\n",
    "\n",
    "    def calConsistencyLoss(self, rhythmsp, pitchsp, liftsp,notesp, gamma=10):\n",
    "        notesp_soft = torch.softmax(notesp, dim=2)\n",
    "        note_flag = notesp_soft[:,:,1]\n",
    "        rhythmsp_soft = torch.softmax(rhythmsp, dim=2)\n",
    "        rhythmsp_note = torch.sum(rhythmsp_soft * self.note_mask, dim=2)\n",
    "\n",
    "        pitchsp_soft = torch.softmax(pitchsp, dim=2)\n",
    "        pitchsp_note = torch.sum(pitchsp_soft[:,:,1:], dim=2)\n",
    "\n",
    "        liftsp_soft = torch.softmax(liftsp, dim=2)\n",
    "        liftsp_note = torch.sum(liftsp_soft[:,:,1:], dim=2)\n",
    "        \n",
    "        loss = gamma * (F.l1_loss(rhythmsp_note, note_flag) + \n",
    "                        F.l1_loss(note_flag, liftsp_note) + \n",
    "                        F.l1_loss(note_flag, pitchsp_note)) / 3.\n",
    "        return loss\n",
    "        \n",
    "def get_decoder(args):\n",
    "    return ScoreDecoder(\n",
    "        ScoreTransformerWrapper(\n",
    "            num_note_tokens=args.num_note_tokens,\n",
    "            num_rhythm_tokens=args.num_rhythm_tokens,\n",
    "            num_pitch_tokens=args.num_pitch_tokens,\n",
    "            num_lift_tokens=args.num_lift_tokens,\n",
    "            max_seq_len=args.max_seq_len,\n",
    "            emb_dim=args.decoder_dim,\n",
    "            attn_layers=Decoder(\n",
    "                dim=args.decoder_dim,\n",
    "                depth=args.decoder_depth,\n",
    "                heads=args.decoder_heads,\n",
    "                **args.decoder_args\n",
    "            )),\n",
    "        pad_value=args.pad_token,\n",
    "        num_rhythmtoken = args.num_rhythmtoken,\n",
    "        noteindexes = args.noteindexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class TrOMR(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.encoder = get_encoder(args)\n",
    "        self.decoder = get_decoder(args)\n",
    "        self.args = args\n",
    "\n",
    "    def forward(self, inputs, rhythms_seq, pitchs_seq, \n",
    "                lifts_seq, note_seq, mask, **kwargs):\n",
    "        \n",
    "        encoded = self.encoder(inputs)\n",
    "        loss = self.decoder(rhythms_seq, pitchs_seq, \n",
    "                            lifts_seq, note_seq, \n",
    "                            context=encoded, mask=mask, **kwargs)\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, x: torch.Tensor, temperature: float = 0.25):\n",
    "        start_token = (\n",
    "                torch.LongTensor([self.args.bos_token]*len(x))[:, None]\n",
    "            ).to(x.device)\n",
    "        nonote_token = (\n",
    "                torch.LongTensor([self.args.nonote_token]*len(x))[:, None]\n",
    "            ).to(x.device)\n",
    "\n",
    "        out_lift, out_pitch, out_rhythm = self.decoder.generate(\n",
    "            start_token, nonote_token , self.args.max_seq_len,\n",
    "            eos_token=self.args.eos_token, context=self.encoder(x), \n",
    "            temperature=temperature)\n",
    "        \n",
    "        return out_lift, out_pitch, out_rhythm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import albumentations as alb\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from einops import rearrange, reduce, repeat\n",
    "\n",
    "# from model import TrOMR\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import TensorDataset  # 텐서데이터셋\n",
    "from torch.utils.data import DataLoader  # 데이터로더\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "class StaffToScore(object):\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.size_h = args.max_height\n",
    "        self.size_w = args.max_width\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = TrOMR(args)\n",
    "        self.model.load_state_dict(torch.load(args.filepaths.checkpoint), strict=True)\n",
    "        # self.model=torch.load(args.filepaths.checkpoint)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        self.lifttokenizer = PreTrainedTokenizerFast(\n",
    "            tokenizer_file=args.filepaths.lifttokenizer\n",
    "        )\n",
    "        self.pitchtokenizer = PreTrainedTokenizerFast(\n",
    "            tokenizer_file=args.filepaths.pitchtokenizer\n",
    "        )\n",
    "        self.rhythmtokenizer = PreTrainedTokenizerFast(\n",
    "            tokenizer_file=args.filepaths.rhythmtokenizer\n",
    "        )\n",
    "        self.notetokenizer = PreTrainedTokenizerFast(\n",
    "            tokenizer_file=args.filepaths.notetokenizer\n",
    "        )\n",
    "        self.transform = alb.Compose(\n",
    "            [\n",
    "                alb.ToGray(always_apply=True),\n",
    "                alb.Normalize((0.7931, 0.7931, 0.7931), (0.1738, 0.1738, 0.1738)),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    \n",
    "\n",
    "    def readimg(self, path):\n",
    "        img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "        # img = cv2.imread(path)\n",
    "        # print(f\"1 -- resize 전\")\n",
    "        # print(img.shape)\n",
    "\n",
    "        if img.shape[-1] == 4:\n",
    "            img = 255 - img[:, :, 3]\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        elif img.shape[-1] == 3:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            raise RuntimeError(\"Unsupport image type!\")\n",
    "        \n",
    "\n",
    "        h, w, c = img.shape\n",
    "\n",
    "        # 이미지의 가로세로 비율 계산\n",
    "        ratio = min(self.size_w / w, self.size_h / h)\n",
    "\n",
    "        # 이미지를 self.size_w 또는 self.size_h에 맞춰서 resize\n",
    "        resized_image = cv2.resize(img, (int(w * ratio), int(h * ratio)))\n",
    "\n",
    "        # 만약 세로 길이가 self.size_h를 넘는다면, 다시 self.size_h에 맞춰서 resize\n",
    "        if resized_image.shape[0] > self.size_h:\n",
    "            ratio = self.size_h / resized_image.shape[0]\n",
    "            resized_image = cv2.resize(resized_image, (int(resized_image.shape[1] * ratio), self.size_h))\n",
    "\n",
    "        img = resized_image\n",
    "\n",
    "        # h, w, c = img.shape\n",
    "        # new_h = self.size_h\n",
    "        # new_w = int(self.size_h / h * w)\n",
    "        # new_w = new_w // self.args.patch_size * self.args.patch_size\n",
    "        # img = cv2.resize(img, (new_w, new_h))\n",
    "\n",
    "        # 이미지 고정 크기로 맞춰야해서...\n",
    "        top_pad = (self.size_h - img.shape[0]) // 2\n",
    "        bottom_pad = self.size_h - img.shape[0] - top_pad\n",
    "        left_pad = (self.size_w - img.shape[1]) // 2\n",
    "        right_pad = self.size_w - img.shape[1] - left_pad\n",
    "        img = np.pad(img, ((top_pad, bottom_pad), (left_pad, right_pad), (0, 0)), mode='constant', constant_values=255)\n",
    "\n",
    "        # print(img)\n",
    "        # print(img.shape)\n",
    "\n",
    "        if \"000051760-1_1_1\" in path:\n",
    "            cv2.imwrite(f\"resize-000051760-1_1_1.png\", img)\n",
    "        img = self.transform(image=img)[\"image\"][:1]\n",
    "\n",
    "        # print(f\"2 -- resize 후\")\n",
    "        # print(img.shape)\n",
    "        # print(img.dtype)\n",
    "        return img\n",
    "\n",
    "    # def preprocessing(self, rgb):\n",
    "    #     patches = rearrange(\n",
    "    #         rgb,\n",
    "    #         \"b c (h s1) (w s2) -> b (h w) (s1 s2 c)\",\n",
    "    #         s1=self.args.patch_size,\n",
    "    #         s2=self.args.patch_size,\n",
    "    #     )\n",
    "    #     return patches\n",
    "    def preprocessing(self, rgb):\n",
    "        h, w, c = rgb.shape\n",
    "        new_h = self.size_h\n",
    "        new_w = int(self.size_h / h * w)\n",
    "        new_w = new_w // self.args.patch_size * self.args.patch_size\n",
    "        img = cv2.resize(rgb, (new_w, new_h))\n",
    "        img = self.transform(image=img)[\"image\"][:1]\n",
    "        return img\n",
    "\n",
    "    def detokenize(self, tokens, tokenizer):\n",
    "        toks = [tokenizer.convert_ids_to_tokens(tok) for tok in tokens]\n",
    "        for b in range(len(toks)):\n",
    "            for i in reversed(range(len(toks[b]))):\n",
    "                if toks[b][i] is None:\n",
    "                    toks[b][i] = \"\"\n",
    "                toks[b][i] = toks[b][i].replace(\"Ġ\", \" \").strip()\n",
    "                if toks[b][i] in ([\"[BOS]\", \"[EOS]\", \"[PAD]\"]):\n",
    "                    del toks[b][i]\n",
    "        return toks\n",
    "    \n",
    "    def entokenize(self, state, tokens, tokenizer):\n",
    "        result=[]\n",
    "        for tok in tokens:\n",
    "            # toks = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(tok))\n",
    "            toks = tokenizer.encode_plus(tok)[\"input_ids\"]\n",
    "            # print(f\"--{state} encode plus: {tokenizer.encode_plus(tok)}\")\n",
    "            # print(\"-- toks len: \", len(toks))\n",
    "            result.append(toks)\n",
    "        return torch.tensor(result)\n",
    "\n",
    "    def all_entokenize(self, lift_y_list, pitch_y_list, rhythm_y_list, note_y_list):\n",
    "        token_lift = self.entokenize(\"lift\", lift_y_list, self.lifttokenizer)\n",
    "        token_pitch = self.entokenize(\"pitch\",pitch_y_list, self.pitchtokenizer)\n",
    "        token_rhythm = self.entokenize(\"rhythm\",rhythm_y_list, self.rhythmtokenizer)\n",
    "        token_note = self.entokenize(\"note\",note_y_list, self.notetokenizer)\n",
    "        return token_lift, token_pitch, token_rhythm, token_note\n",
    "    \n",
    "\n",
    "    def train_model(self, input_seq, lift_seq, pitchs_seq, rhythms_seq, note_seq, mask_seq):\n",
    "        # 역전파 계산\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "\n",
    "        # 데이터 준비 및 학습 반복\n",
    "        num_epochs = 5\n",
    "        batch_size = 32\n",
    "\n",
    "        # 로그 설정\n",
    "        log_date=datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        log_path=f\"../src/workspace/log/train-log_img2score_epoch{num_epochs}-piano-{log_date}.log\"\n",
    "        logging.basicConfig(filename=log_path, level=logging.INFO, format='%(asctime)s : %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "        # for tt in range(rhythms_seq.size()[0]):\n",
    "        #     logging.info(f'리듬은??: {rhythms_seq[tt]}')\n",
    "        #     logging.info(f'리프트는??: {lift_seq[tt]}')\n",
    "        #     logging.info(f'피치는??: {pitchs_seq[tt]}')\n",
    "        #     logging.info(f'마스크는??: {mask_seq[tt]}')\n",
    "\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            for i in tqdm(range(0, len(input_seq), batch_size)):\n",
    "                # input = input_seq.to(self.device)\n",
    "                # lift = lift_seq.to(self.device)\n",
    "                # pitch = pitchs_seq.to(self.device)\n",
    "                # rhythm = rhythms_seq.to(self.device)\n",
    "                # note = note_seq.to(self.device)\n",
    "                # mask = mask_seq.to(self.device)\n",
    "\n",
    "                max_data_len=min(len(input_seq), i+batch_size)\n",
    "\n",
    "                inputs_batch = input_seq[i:max_data_len].to(self.device)\n",
    "                lift_seq_batch = lift_seq[i:max_data_len].to(self.device)\n",
    "                pitchs_seq_batch = pitchs_seq[i:max_data_len].to(self.device)\n",
    "                rhythms_seq_batch = rhythms_seq[i:max_data_len].to(self.device)\n",
    "                note_seq_batch = note_seq[i:max_data_len].to(self.device)\n",
    "                mask_batch = mask_seq[i:max_data_len].to(self.device)\n",
    "\n",
    "                outputs = self.model.forward(inputs_batch, rhythms_seq_batch, pitchs_seq_batch, lift_seq_batch, note_seq_batch, mask=mask_batch)\n",
    "\n",
    "                # λ = 0.1 and β = 1.0.\n",
    "                # LTrOMR = λLce + βLcon\n",
    "                alpha = 0.1\n",
    "                beta = 1.0\n",
    "                loss = alpha*(outputs['loss_rhythm'] + outputs['loss_pitch'] + outputs['loss_lift']) + beta*outputs['loss_consist']\n",
    "\n",
    "                # 역전파 단계\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # 훈련 과정을 출력\n",
    "                print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "                print(f\"-- consist Loss({outputs['loss_consist']:.4f}) | rhythm Loss({outputs['loss_rhythm']:.4f}) | pitch Loss({outputs['loss_pitch']:.4f}) | lift loss({outputs['loss_lift']:.4f})\")\n",
    "\n",
    "                # 로그 기록\n",
    "                logging.info(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "                logging.info(f\"-- consist Loss({outputs['loss_consist']:.4f}) | rhythm Loss({outputs['loss_rhythm']:.4f}) | pitch Loss({outputs['loss_pitch']:.4f}) | lift loss({outputs['loss_lift']:.4f})\")\n",
    "            \n",
    "\n",
    "        # 체크포인트 저장\n",
    "        datet=datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        checkpoint_path = f'../src/workspace/checkpoints/img2score_epoch{num_epochs}-piano-{datet}.pth'\n",
    "        torch.save(self.model.state_dict(), checkpoint_path)\n",
    "        print(f'--!! saved {checkpoint_path}')\n",
    "        logging.info(f'Saved checkpoint: {checkpoint_path}')\n",
    "\n",
    "    # def predict_img2token(self, rgbimgs):\n",
    "    #     if not isinstance(rgbimgs, list):\n",
    "    #         rgbimgs = [rgbimgs]\n",
    "    #     imgs = [self.preprocessing(item) for item in rgbimgs]\n",
    "    #     imgs = torch.cat(imgs).float().unsqueeze(1)\n",
    "    #     output = self.model.generate(\n",
    "    #         imgs.to(self.device), temperature=self.args.get(\"temperature\", 0.2)\n",
    "    #     )\n",
    "    #     rhythm, pitch, lift = output\n",
    "    #     return rhythm, pitch, lift\n",
    "    \n",
    "    def predict_token(self, imgpath):\n",
    "        imgs = []\n",
    "        if os.path.isdir(imgpath):\n",
    "            for item in os.listdir(imgpath):\n",
    "                imgs.append(self.readimg(os.path.join(imgpath, item)))\n",
    "        else:\n",
    "            imgs.append(self.readimg(imgpath))\n",
    "        imgs = torch.cat(imgs).float().unsqueeze(1)\n",
    "        output = self.model.generate(\n",
    "            imgs.to(self.device), temperature=self.args.get(\"temperature\", 0.2)\n",
    "        )\n",
    "        rhythm, pitch, lift = output\n",
    "        return rhythm, pitch, lift\n",
    "\n",
    "    def predict(self, imgpath):\n",
    "        rhythm, pitch, lift = self.predict_token(imgpath)\n",
    "\n",
    "        predlift = self.detokenize(lift, self.lifttokenizer)\n",
    "        predpitch = self.detokenize(pitch, self.pitchtokenizer)\n",
    "        predrhythm = self.detokenize(rhythm, self.rhythmtokenizer)\n",
    "        return predrhythm, predpitch, predlift\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "\n",
    "def getconfig(configpath):\n",
    "    args = OmegaConf.load(configpath)\n",
    "\n",
    "    workspace = os.path.dirname(configpath)\n",
    "    for key in args.filepaths.keys():\n",
    "        args.filepaths[key] = os.path.join(workspace, args.filepaths[key])\n",
    "    return args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 7 ['../data/raw/PrIMuS/package_aa_short/000102292-1_1_1/000102292-1_1_1.png', '../data/raw/PrIMuS/package_aa_short/000102289-5_1_1/000102289-5_1_1.png', '../data/raw/PrIMuS/package_aa_short/000102293-1_1_1/000102293-1_1_1.png', '../data/raw/PrIMuS/package_aa_short/000102291-1_1_1/000102291-1_1_1.png', '../data/raw/PrIMuS/package_aa_short/000102291-1_1_2/000102291-1_1_2.png', '../data/raw/PrIMuS/package_aa_short/000102289-4_1_1/000102289-4_1_1.png', '../data/raw/PrIMuS/package_aa_short/000102289-3_1_1/000102289-3_1_1.png']\n",
      "y: 7 ['../data/raw/PrIMuS/package_aa_short/000102292-1_1_1/000102292-1_1_1.semantic', '../data/raw/PrIMuS/package_aa_short/000102289-5_1_1/000102289-5_1_1.semantic', '../data/raw/PrIMuS/package_aa_short/000102293-1_1_1/000102293-1_1_1.semantic', '../data/raw/PrIMuS/package_aa_short/000102291-1_1_1/000102291-1_1_1.semantic', '../data/raw/PrIMuS/package_aa_short/000102291-1_1_2/000102291-1_1_2.semantic', '../data/raw/PrIMuS/package_aa_short/000102289-4_1_1/000102289-4_1_1.semantic', '../data/raw/PrIMuS/package_aa_short/000102289-3_1_1/000102289-3_1_1.semantic']\n",
      "x: torch.Size([7, 1, 128, 1280])\n",
      "y: torch.Size([7, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.0434\n",
      "-- consist Loss(0.0035) | rhythm Loss(0.1591) | pitch Loss(0.1774) | lift loss(0.0625)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Loss: 0.0733\n",
      "-- consist Loss(0.0343) | rhythm Loss(0.1545) | pitch Loss(0.1748) | lift loss(0.0615)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Loss: 0.0666\n",
      "-- consist Loss(0.0278) | rhythm Loss(0.1517) | pitch Loss(0.1743) | lift loss(0.0618)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Loss: 0.0511\n",
      "-- consist Loss(0.0123) | rhythm Loss(0.1509) | pitch Loss(0.1752) | lift loss(0.0620)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 0.0452\n",
      "-- consist Loss(0.0061) | rhythm Loss(0.1512) | pitch Loss(0.1770) | lift loss(0.0621)\n",
      "--!! saved ../src/workspace/checkpoints/img2score_epoch5-piano-2024-05-14_20-37-07.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "import argparse\n",
    "from random import randrange\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cofigpath = \"../src/workspace/config.yaml\" \n",
    "    args = getconfig(cofigpath)\n",
    "\n",
    "    handler = StaffToScore(args)\n",
    "    \n",
    "    x_dataset_path=f\"{DATA_RAW_PATH}/{PrIMuS}/{package_aa}/\"\n",
    "    x_all_dataset_path = glob.glob(f\"{x_dataset_path}/*\")\n",
    "    del x_dataset_path\n",
    "    x_pattern = re.compile(r'^[^._].*\\.png$') \n",
    "    y_pattern = re.compile(r'^[^._].*\\.semantic$')\n",
    "\n",
    "    x_raw_file_list=[]  # image\n",
    "    y_raw_file_list=[]  # label\n",
    "    for x_path in x_all_dataset_path:\n",
    "        files = os.listdir(x_path)\n",
    "        x_filtered_files = [f\"{x_path}/{file}\" for file in files if x_pattern.match(file)]\n",
    "        y_filtered_files = [f\"{x_path}/{file}\" for file in files if y_pattern.match(file)]\n",
    "        if len(x_filtered_files) == len(y_filtered_files):\n",
    "            x_raw_file_list+=x_filtered_files\n",
    "            y_raw_file_list+=y_filtered_files\n",
    "\n",
    "    del x_all_dataset_path\n",
    "    print(\"x:\",len(x_raw_file_list),x_raw_file_list)\n",
    "    print(\"y:\",len(y_raw_file_list),y_raw_file_list)\n",
    "\n",
    "    def convert_img(imgpath):\n",
    "        imgs = []\n",
    "        # if os.path.isdir(imgpath):\n",
    "        for item in imgpath:\n",
    "            # print(\"---\", item, \"---\")\n",
    "            con_img=handler.readimg(item)\n",
    "            imgs.append(con_img)\n",
    "\n",
    "        imgs = torch.cat(imgs).float().unsqueeze(1)\n",
    "\n",
    "        return imgs\n",
    "    \n",
    "\n",
    "    def read_txt_file(file_path):\n",
    "        \"\"\"\n",
    "        텍스트 파일을 읽어서 내용을 리스트로 반환하는 함수\n",
    "        \"\"\"\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.readlines()\n",
    "            # 각 줄의 개행 문자 제거\n",
    "            content = [line.strip() for line in content]\n",
    "        return content[0]\n",
    "    \n",
    "\n",
    "    # print(f\"------------------y data----------------------------\")\n",
    "    # print(f\"-- labeling y : {len(contents)}\")\n",
    "    # print(f\"-- labeling y : {contents[0]}\")\n",
    "    # print(f\"----------------------------------------------------\")\n",
    "\n",
    "    \n",
    "    # 각 token에 맞는 string list로 만들기\n",
    "    def map_pitch(note):\n",
    "        pitch_mapping = {\n",
    "            # \"nonote\": 0,\n",
    "            \"note-C0\": 1,\n",
    "            \"note-D0\": 2,\n",
    "            \"note-E0\": 3,\n",
    "            \"note-F0\": 4,\n",
    "            \"note-G0\": 5,\n",
    "            \"note-A0\": 6,\n",
    "            \"note-B0\": 7,\n",
    "            \"note-C1\": 8,\n",
    "            \"note-D1\": 9,\n",
    "            \"note-E1\": 10,\n",
    "            \"note-F1\": 11,\n",
    "            \"note-G1\": 12,\n",
    "            \"note-A1\": 13,\n",
    "            \"note-B1\": 14,\n",
    "            \"note-C2\": 15,\n",
    "            \"note-D2\": 16,\n",
    "            \"note-E2\": 17,\n",
    "            \"note-F2\": 18,\n",
    "            \"note-G2\": 19,\n",
    "            \"note-A2\": 20,\n",
    "            \"note-B2\": 21,\n",
    "            \"note-C3\": 22,\n",
    "            \"note-D3\": 23,\n",
    "            \"note-E3\": 24,\n",
    "            \"note-F3\": 25,\n",
    "            \"note-G3\": 26,\n",
    "            \"note-A3\": 27,\n",
    "            \"note-B3\": 28,\n",
    "            \"note-C4\": 29,\n",
    "            \"note-D4\": 30,\n",
    "            \"note-E4\": 31,\n",
    "            \"note-F4\": 32,\n",
    "            \"note-G4\": 33,\n",
    "            \"note-A4\": 34,\n",
    "            \"note-B4\": 35,\n",
    "            \"note-C5\": 36,\n",
    "            \"note-D5\": 37,\n",
    "            \"note-E5\": 38,\n",
    "            \"note-F5\": 39,\n",
    "            \"note-G5\": 40,\n",
    "            \"note-A5\": 41,\n",
    "            \"note-B5\": 42,\n",
    "            \"note-C6\": 43,\n",
    "            \"note-D6\": 44,\n",
    "            \"note-E6\": 45,\n",
    "            \"note-F6\": 46,\n",
    "            \"note-G6\": 47,\n",
    "            \"note-A6\": 48,\n",
    "            \"note-B6\": 49,\n",
    "            \"note-C7\": 50,\n",
    "            \"note-D7\": 51,\n",
    "            \"note-E7\": 52,\n",
    "            \"note-F7\": 53,\n",
    "            \"note-G7\": 54,\n",
    "            \"note-A7\": 55,\n",
    "            \"note-B7\": 56,\n",
    "            \"note-C8\": 57,\n",
    "            \"note-D8\": 58,\n",
    "            \"note-E8\": 59,\n",
    "            \"note-F8\": 60,\n",
    "            \"note-G8\": 61,\n",
    "            \"note-A8\": 62,\n",
    "            \"note-B8\": 63,\n",
    "            \"note-C9\": 64,\n",
    "            \"note-D9\": 65,\n",
    "            \"note-E9\": 66,\n",
    "            \"note-F9\": 67,\n",
    "            \"note-G9\": 68,\n",
    "            \"note-A9\": 69,\n",
    "            \"note-B9\": 70\n",
    "        }\n",
    "        return \"nonote\" if note not in pitch_mapping else note\n",
    "    \n",
    "    def map_rhythm(note):\n",
    "        duration_mapping =  {\n",
    "            \"[PAD]\": 0,\n",
    "            \"[BOS]\": 1,\n",
    "            \"[EOS]\": 2,\n",
    "            \"+\": 3,\n",
    "            \"|\": 4,\n",
    "            \"barline\": 5,\n",
    "            \"clef-C1\": 6,\n",
    "            \"clef-C2\": 7,\n",
    "            \"clef-C3\": 8,\n",
    "            \"clef-C4\": 9,\n",
    "            \"clef-C5\": 10,\n",
    "            \"clef-F3\": 11,\n",
    "            \"clef-F4\": 12,\n",
    "            \"clef-F5\": 13,\n",
    "            \"clef-G1\": 14,\n",
    "            \"clef-G2\": 15,\n",
    "            \"keySignature-AM\": 16,\n",
    "            \"keySignature-AbM\": 17,\n",
    "            \"keySignature-BM\": 18,\n",
    "            \"keySignature-BbM\": 19,\n",
    "            \"keySignature-C#M\": 20,\n",
    "            \"keySignature-CM\": 21,\n",
    "            \"keySignature-CbM\": 22,\n",
    "            \"keySignature-DM\": 23,\n",
    "            \"keySignature-DbM\": 24,\n",
    "            \"keySignature-EM\": 25,\n",
    "            \"keySignature-EbM\": 26,\n",
    "            \"keySignature-F#M\": 27,\n",
    "            \"keySignature-FM\": 28,\n",
    "            \"keySignature-GM\": 29,\n",
    "            \"keySignature-GbM\": 30,\n",
    "            \"multirest-10\": 31,\n",
    "            \"multirest-100\": 32,\n",
    "            \"multirest-11\": 33,\n",
    "            \"multirest-111\": 34,\n",
    "            \"multirest-116\": 35,\n",
    "            \"multirest-12\": 36,\n",
    "            \"multirest-120\": 37,\n",
    "            \"multirest-121\": 38,\n",
    "            \"multirest-129\": 39,\n",
    "            \"multirest-13\": 40,\n",
    "            \"multirest-133\": 41,\n",
    "            \"multirest-135\": 42,\n",
    "            \"multirest-14\": 43,\n",
    "            \"multirest-140\": 44,\n",
    "            \"multirest-144\": 45,\n",
    "            \"multirest-15\": 46,\n",
    "            \"multirest-152\": 47,\n",
    "            \"multirest-154\": 48,\n",
    "            \"multirest-16\": 49,\n",
    "            \"multirest-17\": 50,\n",
    "            \"multirest-174\": 51,\n",
    "            \"multirest-18\": 52,\n",
    "            \"multirest-19\": 53,\n",
    "            \"multirest-195\": 54,\n",
    "            \"multirest-196\": 55,\n",
    "            \"multirest-2\": 56,\n",
    "            \"multirest-20\": 57,\n",
    "            \"multirest-21\": 58,\n",
    "            \"multirest-22\": 59,\n",
    "            \"multirest-224\": 60,\n",
    "            \"multirest-23\": 61,\n",
    "            \"multirest-24\": 62,\n",
    "            \"multirest-249\": 63,\n",
    "            \"multirest-25\": 64,\n",
    "            \"multirest-26\": 65,\n",
    "            \"multirest-27\": 66,\n",
    "            \"multirest-28\": 67,\n",
    "            \"multirest-29\": 68,\n",
    "            \"multirest-3\": 69,\n",
    "            \"multirest-30\": 70,\n",
    "            \"multirest-31\": 71,\n",
    "            \"multirest-32\": 72,\n",
    "            \"multirest-33\": 73,\n",
    "            \"multirest-34\": 74,\n",
    "            \"multirest-35\": 75,\n",
    "            \"multirest-36\": 76,\n",
    "            \"multirest-37\": 77,\n",
    "            \"multirest-38\": 78,\n",
    "            \"multirest-39\": 79,\n",
    "            \"multirest-4\": 80,\n",
    "            \"multirest-40\": 81,\n",
    "            \"multirest-41\": 82,\n",
    "            \"multirest-42\": 83,\n",
    "            \"multirest-43\": 84,\n",
    "            \"multirest-44\": 85,\n",
    "            \"multirest-444\": 86,\n",
    "            \"multirest-446\": 87,\n",
    "            \"multirest-45\": 88,\n",
    "            \"multirest-46\": 89,\n",
    "            \"multirest-47\": 90,\n",
    "            \"multirest-48\": 91,\n",
    "            \"multirest-49\": 92,\n",
    "            \"multirest-5\": 93,\n",
    "            \"multirest-50\": 94,\n",
    "            \"multirest-51\": 95,\n",
    "            \"multirest-52\": 96,\n",
    "            \"multirest-54\": 97,\n",
    "            \"multirest-55\": 98,\n",
    "            \"multirest-559\": 99,\n",
    "            \"multirest-56\": 100,\n",
    "            \"multirest-58\": 101,\n",
    "            \"multirest-6\": 102,\n",
    "            \"multirest-60\": 103,\n",
    "            \"multirest-62\": 104,\n",
    "            \"multirest-63\": 105,\n",
    "            \"multirest-64\": 106,\n",
    "            \"multirest-67\": 107,\n",
    "            \"multirest-68\": 108,\n",
    "            \"multirest-69\": 109,\n",
    "            \"multirest-7\": 110,\n",
    "            \"multirest-70\": 111,\n",
    "            \"multirest-72\": 112,\n",
    "            \"multirest-74\": 113,\n",
    "            \"multirest-75\": 114,\n",
    "            \"multirest-78\": 115,\n",
    "            \"multirest-79\": 116,\n",
    "            \"multirest-8\": 117,\n",
    "            \"multirest-82\": 118,\n",
    "            \"multirest-83\": 119,\n",
    "            \"multirest-87\": 120,\n",
    "            \"multirest-88\": 121,\n",
    "            \"multirest-89\": 122,\n",
    "            \"multirest-9\": 123,\n",
    "            \"multirest-90\": 124,\n",
    "            \"multirest-92\": 125,\n",
    "            \"multirest-93\": 126,\n",
    "            \"multirest-94\": 127,\n",
    "            \"multirest-98\": 128,\n",
    "            \"note-breve\": 129,\n",
    "            \"note-breve.\": 130,\n",
    "            \"note-eighth\": 131,\n",
    "            \"note-eighth.\": 132,\n",
    "            \"note-half\": 133,\n",
    "            \"note-half.\": 134,\n",
    "            \"note-hundred_twenty_eighth\": 135,\n",
    "            \"note-long\": 136,\n",
    "            \"note-quarter\": 137,\n",
    "            \"note-quarter.\": 138,\n",
    "            \"note-sixteenth\": 139,\n",
    "            \"note-sixteenth.\": 140,\n",
    "            \"note-sixty_fourth\": 141,\n",
    "            \"note-sixty_fourth.\": 142,\n",
    "            \"note-thirty_second\": 143,\n",
    "            \"note-thirty_second.\": 144,\n",
    "            \"note-whole\": 145,\n",
    "            \"note-whole.\": 146,\n",
    "            \"rest-256th\": 147,\n",
    "            \"rest-512th\": 148,\n",
    "            \"rest-breve\": 149,\n",
    "            \"rest-eighth\": 150,\n",
    "            \"rest-eighth.\": 151,\n",
    "            \"rest-half\": 152,\n",
    "            \"rest-half.\": 153,\n",
    "            \"rest-hundred_twenty_eighth\": 154,\n",
    "            \"rest-long\": 155,\n",
    "            \"rest-quarter\": 156,\n",
    "            \"rest-quarter.\": 157,\n",
    "            \"rest-sixteenth\": 158,\n",
    "            \"rest-sixteenth.\": 159,\n",
    "            \"rest-sixty_fourth\": 160,\n",
    "            \"rest-sixty_fourth.\": 161,\n",
    "            \"rest-thirty_second\": 162,\n",
    "            \"rest-thirty_second.\": 163,\n",
    "            \"rest-whole\": 164,\n",
    "            \"rest-whole.\": 165,\n",
    "            \"timeSignature-1/16\": 166,\n",
    "            \"timeSignature-1/2\": 167,\n",
    "            \"timeSignature-1/4\": 168,\n",
    "            \"timeSignature-1/8\": 169,\n",
    "            \"timeSignature-10/1\": 170,\n",
    "            \"timeSignature-10/16\": 171,\n",
    "            \"timeSignature-10/4\": 172,\n",
    "            \"timeSignature-10/8\": 173,\n",
    "            \"timeSignature-100/2\": 174,\n",
    "            \"timeSignature-11/16\": 175,\n",
    "            \"timeSignature-11/4\": 176,\n",
    "            \"timeSignature-11/8\": 177,\n",
    "            \"timeSignature-12/16\": 178,\n",
    "            \"timeSignature-12/32\": 179,\n",
    "            \"timeSignature-12/4\": 180,\n",
    "            \"timeSignature-12/8\": 181,\n",
    "            \"timeSignature-13/16\": 182,\n",
    "            \"timeSignature-13/4\": 183,\n",
    "            \"timeSignature-13/8\": 184,\n",
    "            \"timeSignature-14/4\": 185,\n",
    "            \"timeSignature-14/8\": 186,\n",
    "            \"timeSignature-15/16\": 187,\n",
    "            \"timeSignature-15/4\": 188,\n",
    "            \"timeSignature-15/8\": 189,\n",
    "            \"timeSignature-16/16\": 190,\n",
    "            \"timeSignature-16/4\": 191,\n",
    "            \"timeSignature-16/8\": 192,\n",
    "            \"timeSignature-17/16\": 193,\n",
    "            \"timeSignature-17/4\": 194,\n",
    "            \"timeSignature-17/8\": 195,\n",
    "            \"timeSignature-18/16\": 196,\n",
    "            \"timeSignature-18/4\": 197,\n",
    "            \"timeSignature-18/8\": 198,\n",
    "            \"timeSignature-19/16\": 199,\n",
    "            \"timeSignature-19/32\": 200,\n",
    "            \"timeSignature-19/4\": 201,\n",
    "            \"timeSignature-2/1\": 202,\n",
    "            \"timeSignature-2/16\": 203,\n",
    "            \"timeSignature-2/2\": 204,\n",
    "            \"timeSignature-2/32\": 205,\n",
    "            \"timeSignature-2/4\": 206,\n",
    "            \"timeSignature-2/8\": 207,\n",
    "            \"timeSignature-20/4\": 208,\n",
    "            \"timeSignature-20/8\": 209,\n",
    "            \"timeSignature-21/16\": 210,\n",
    "            \"timeSignature-22/16\": 211,\n",
    "            \"timeSignature-23/16\": 212,\n",
    "            \"timeSignature-23/4\": 213,\n",
    "            \"timeSignature-23/8\": 214,\n",
    "            \"timeSignature-24/16\": 215,\n",
    "            \"timeSignature-24/4\": 216,\n",
    "            \"timeSignature-27/16\": 217,\n",
    "            \"timeSignature-29/4\": 218,\n",
    "            \"timeSignature-3/1\": 219,\n",
    "            \"timeSignature-3/16\": 220,\n",
    "            \"timeSignature-3/2\": 221,\n",
    "            \"timeSignature-3/4\": 222,\n",
    "            \"timeSignature-3/8\": 223,\n",
    "            \"timeSignature-32/8\": 224,\n",
    "            \"timeSignature-33/32\": 225,\n",
    "            \"timeSignature-35/16\": 226,\n",
    "            \"timeSignature-35/32\": 227,\n",
    "            \"timeSignature-37/16\": 228,\n",
    "            \"timeSignature-4/1\": 229,\n",
    "            \"timeSignature-4/16\": 230,\n",
    "            \"timeSignature-4/2\": 231,\n",
    "            \"timeSignature-4/4\": 232,\n",
    "            \"timeSignature-4/8\": 233,\n",
    "            \"timeSignature-5/16\": 234,\n",
    "            \"timeSignature-5/2\": 235,\n",
    "            \"timeSignature-5/4\": 236,\n",
    "            \"timeSignature-5/8\": 237,\n",
    "            \"timeSignature-52/4\": 238,\n",
    "            \"timeSignature-6/16\": 239,\n",
    "            \"timeSignature-6/2\": 240,\n",
    "            \"timeSignature-6/4\": 241,\n",
    "            \"timeSignature-6/8\": 242,\n",
    "            \"timeSignature-63/4\": 243,\n",
    "            \"timeSignature-7/1\": 244,\n",
    "            \"timeSignature-7/16\": 245,\n",
    "            \"timeSignature-7/2\": 246,\n",
    "            \"timeSignature-7/4\": 247,\n",
    "            \"timeSignature-7/8\": 248,\n",
    "            \"timeSignature-8/16\": 249,\n",
    "            \"timeSignature-8/2\": 250,\n",
    "            \"timeSignature-8/4\": 251,\n",
    "            \"timeSignature-8/8\": 252,\n",
    "            \"timeSignature-80/4\": 253,\n",
    "            \"timeSignature-9/16\": 254,\n",
    "            \"timeSignature-9/32\": 255,\n",
    "            \"timeSignature-9/4\": 256,\n",
    "            \"timeSignature-9/8\": 257,\n",
    "            \"timeSignature-C\": 258,\n",
    "            \"timeSignature-C/\": 259,\n",
    "            \"clef-percussion\": 260\n",
    "        }\n",
    "        return note if note in duration_mapping else \"<unk>\"\n",
    "\n",
    "    def map_lift(note):\n",
    "        lift_mapping =  {\n",
    "            # \"nonote\"    : 0,\n",
    "            \"lift_null\" : 1,\n",
    "            \"lift_##\"   : 2,\n",
    "            \"lift_#\"    : 3,\n",
    "            \"lift_bb\"   : 4,\n",
    "            \"lift_b\"    : 5,\n",
    "            \"lift_N\"    : 6\n",
    "        }\n",
    "        return \"nonote\" if note not in lift_mapping else note\n",
    "        \n",
    "    def symbol2pitch_rhythm_lift(symbol_lift, symbol_pitch, symbol_rhythm):\n",
    "        return map_lift(symbol_lift), map_pitch(symbol_pitch), map_rhythm(symbol_rhythm)\n",
    "    \n",
    "    def note2pitch_rhythm_lift(note):\n",
    "        # note-G#3_eighth\n",
    "        note_split = note.split(\"_\") # (note-G#3) (eighth)\n",
    "        note_pitch_lift = note_split[:1][0]\n",
    "        note_rhythm = note_split[1:][0]\n",
    "        rhythm=f\"note-{note_rhythm}\"\n",
    "        # print(\"-- note_rhythm: \", rhythm)\n",
    "\n",
    "        note_note, pitch_lift = note_pitch_lift.split(\"-\") # (note) (G#3)\n",
    "        if len(pitch_lift)>2:\n",
    "            pitch = f\"note-{pitch_lift[0]+pitch_lift[-1]}\" # (G3)\n",
    "            lift = f\"lift_{pitch_lift[1:-1]}\"\n",
    "        else:\n",
    "            pitch = f\"note-{pitch_lift}\" \n",
    "            lift = f\"lift_null\"\n",
    "        # print(\"-- note_pitch_lift: \", pitch, lift)\n",
    "        return symbol2pitch_rhythm_lift(lift, pitch, rhythm)\n",
    "    \n",
    "    def rest2pitch_rhythm_lift(rest):\n",
    "        # rest-quarter\n",
    "        return symbol2pitch_rhythm_lift(\"nonote\", \"nonote\", rest)\n",
    "    \n",
    "    def map_pitch2isnote(pitch_note):\n",
    "        group_notes = []\n",
    "        note_split = pitch_note.split(\"+\")\n",
    "        for note_s in note_split:\n",
    "            if \"nonote\" in note_s:\n",
    "                group_notes.append(\"nonote\")\n",
    "            elif \"note-\" in note_s:\n",
    "                group_notes.append(\"note\")\n",
    "        return \"+\".join(group_notes)\n",
    "\n",
    "\n",
    "    def map_notes2pitch_rhythm_lift_note(note_list):\n",
    "        result_lift=[]\n",
    "        result_pitch=[]\n",
    "        result_rhythm=[]\n",
    "        result_note=[]\n",
    "\n",
    "        for notes in note_list:\n",
    "            group_lift = []\n",
    "            group_pitch = []\n",
    "            group_rhythm = []\n",
    "            group_notes_token_len=0\n",
    "\n",
    "            # 우선 +로 나누고, 안에 | 있는 지 확인해서 먼저 붙이기\n",
    "            # note-G#3_eighth + note-G3_eighth + note-G#3_eighth|note-G#3_eighth + rest-quarter\n",
    "            note_split = notes.split(\"+\")\n",
    "            for note_s in note_split:\n",
    "                if \"|\" in note_s:\n",
    "                    mapped_lift_chord = []\n",
    "                    mapped_pitch_chord = []\n",
    "                    mapped_rhythm_chord = []\n",
    "                    \n",
    "                    # note-G#3_eighth|note-G#3_eighth\n",
    "                    note_split_chord = note_s.split(\"|\") # (note-G#3_eighth) (note-G#3_eighth)\n",
    "                    for idx, note_s_c in enumerate(note_split_chord):\n",
    "                        chord_lift, chord_pitch, chord_rhythm = note2pitch_rhythm_lift(note_s_c)\n",
    "\n",
    "                        mapped_lift_chord.append(chord_lift)\n",
    "                        mapped_pitch_chord.append(chord_pitch)\n",
    "                        mapped_rhythm_chord.append(chord_rhythm)\n",
    "\n",
    "                        # --> '|' 도 token이기 때문에 lift, pitch엔 nonote 추가해주기\n",
    "                        if idx != len(note_split_chord)-1:\n",
    "                            mapped_lift_chord.append(\"nonote\")\n",
    "                            mapped_pitch_chord.append(\"nonote\")\n",
    "\n",
    "                    group_lift.append(\"+\".join(mapped_lift_chord))\n",
    "                    group_pitch.append(\"+\".join(mapped_pitch_chord))\n",
    "                    group_rhythm.append(\"|\".join(mapped_rhythm_chord))\n",
    "\n",
    "                    # --> '|' 도 token이기 때문에 추가된 token 개수 더하기\n",
    "                    # 동시에 친 걸 하나의 string으로 해버리는 거니까 주의하기\n",
    "                    group_notes_token_len+=len(note_split_chord) + len(note_split_chord)-1\n",
    "\n",
    "                elif \"note\" in note_s:\n",
    "                    if \"_\" in note_s:\n",
    "                        # note-G#3_eighth\n",
    "                        note2lift, note2pitch, note2rhythm = note2pitch_rhythm_lift(note_s)\n",
    "                        group_lift.append(note2lift)\n",
    "                        group_pitch.append(note2pitch)\n",
    "                        group_rhythm.append(note2rhythm)\n",
    "                        group_notes_token_len+=1\n",
    "                \n",
    "                elif \"rest\" in note_s:\n",
    "                    if \"-\" in note_s:\n",
    "                        # rest-quarter\n",
    "                        rest2lift, rest2pitch, rest2rhythm =rest2pitch_rhythm_lift(note_s)\n",
    "                        group_lift.append(rest2lift)\n",
    "                        group_pitch.append(rest2pitch)\n",
    "                        group_rhythm.append(rest2rhythm)\n",
    "                        group_notes_token_len+=1\n",
    "                else:\n",
    "                    # clef-F4+keySignature-AM+timeSignature-12/8\n",
    "                    symbol2lift, symbol2pitch, symbol2rhythm = symbol2pitch_rhythm_lift(\"nonote\", \"nonote\", note_s)\n",
    "                    group_lift.append(symbol2lift)\n",
    "                    group_pitch.append(symbol2pitch)\n",
    "                    group_rhythm.append(symbol2rhythm)\n",
    "                    group_notes_token_len+=1\n",
    "\n",
    "            toks_len= group_notes_token_len\n",
    "\n",
    "            # lift, pitch\n",
    "            emb_lift=\"nonote+\"\n",
    "            emb_pitch=\"nonote+\"\n",
    "            emb_lift+= \"+\".join(group_lift)\n",
    "            emb_pitch+= \"+\".join(group_pitch)\n",
    "            emb_lift+=\"+nonote\"\n",
    "            emb_pitch+=\"+nonote\"\n",
    "\n",
    "            # rhythm\n",
    "            emb_rhythm=\"[BOS]\"\n",
    "            emb_rhythm+= \"+\".join(group_rhythm)\n",
    "            emb_rhythm+=\"[EOS]\"\n",
    "\n",
    "            # 뒤에 남은 건 패딩\n",
    "            if toks_len < 256 - 2:\n",
    "                for _ in range(256 - toks_len - 2):\n",
    "                    emb_lift+=\"+nonote\"\n",
    "                    emb_pitch+=\"+nonote\"        \n",
    "                    emb_rhythm+=\"[PAD]\"\n",
    "\n",
    "            result_lift.append(emb_lift)\n",
    "            result_pitch.append(emb_pitch)\n",
    "            result_rhythm.append(emb_rhythm)\n",
    "            result_note.append(map_pitch2isnote(emb_pitch))\n",
    "\n",
    "        return result_lift, result_pitch, result_rhythm, result_note\n",
    "    def get_mask(token_rhythm):\n",
    "        result = []\n",
    "        for tokens in token_rhythm:\n",
    "            re=[0 for _ in range(len(tokens))]\n",
    "            for idx, to in enumerate(tokens):\n",
    "                if to !=0:\n",
    "                    re[idx]=1\n",
    "            result.append(re)\n",
    "        return torch.tensor(result)\n",
    "    # ===============================================================================\n",
    "    # \"\"\"\n",
    "    # 1 -- resize 전\n",
    "    # (298, 2404, 4)\n",
    "    # 2 -- resize 후\n",
    "    # torch.Size([1, 128, 1024])\n",
    "    # torch.float32\n",
    "    # rgbimgs : torch.Size([1, 1, 128, 1024])\n",
    "    # \"\"\"\n",
    "\n",
    "    batch_=1000\n",
    "    for i in range(0, len(x_raw_file_list), batch_):\n",
    "        max_data_len=min(len(x_raw_file_list), i+batch_)\n",
    "\n",
    "        x_file_list=x_raw_file_list[i:max_data_len]\n",
    "        y_file_list=y_raw_file_list[i:max_data_len]\n",
    "\n",
    "        inputs=convert_img(x_file_list)\n",
    "        del x_file_list\n",
    "\n",
    "        # 각 파일의 내용을 담을 리스트\n",
    "        contents = []\n",
    "        # 각 파일을 읽어서 내용을 리스트에 추가\n",
    "        for annotation_path in y_file_list:\n",
    "            # print(\"--- annotation_path:\", annotation_path)\n",
    "            content = read_txt_file(annotation_path)\n",
    "            # 사이사이에 + 로 연결해주기\n",
    "            content=content.replace(\" \",\"+\")\n",
    "            content=content.replace(\"\\t\",\"+\")\n",
    "            contents.append(content)\n",
    "        del y_file_list\n",
    "\n",
    "        result_lift, result_pitch, result_rhythm, result_note = map_notes2pitch_rhythm_lift_note(contents)\n",
    "        # print(len(result_lift), len(result_pitch), len(result_rhythm), len(result_note))\n",
    "\n",
    "        token_lift, token_pitch, token_rhythm, token_note = handler.all_entokenize(result_lift, result_pitch, result_rhythm, result_note)\n",
    "        del result_lift, result_pitch, result_rhythm, result_note\n",
    "\n",
    "        # 부울 형식으로 변환\n",
    "        mask = get_mask(token_rhythm).bool()\n",
    "\n",
    "        print(\"x:\", inputs.size())\n",
    "        print(\"y:\", token_lift.size())\n",
    "\n",
    "        \n",
    "\n",
    "        handler.train_model(inputs, token_lift, token_pitch, token_rhythm, token_note, mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Symbol Error Rate (SER): 0.1\n",
      "-- Result:  ['clef-G2+timeSignature-C/+nonote_quarter+nonote_quarter+nonote_quarter+nonote_eighth+note-B4_eighth+note-A4_eighth+note-C5_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+note-A4_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+note-B4_eighth+nonote_eighth+nonote_eighth+nonote_eighth+note-C5_eighth+nonote_eighth+nonote_eighth+note-A4_eighth+nonote_eighth+nonote_eighth+nonote_eighth+note-D5_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+note-D5_eighth+note-D5_eighth+note-G4_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+note-C5_eighth+nonote_eighth+note-A4_eighth+note-A4_eighth+nonote_eighth+nonote_eighth+nonote_eighth+note-G4_eighth+note-E5_eighth+nonote_eighth+nonote_eighth+note-C5_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+note-B4_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+note-D5_eighth+nonote_eighth+nonote_eighth+nonote_eighth+note-B4_eighth+nonote_eighth+note-E5_eighth+nonote_eighth+note-D5_eighth+note-A4_eighth+note-A4_eighth+nonote_eighth+note-G4_eighth+note-C5_eighth+nonote_eighth+note-A4_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+note-B4_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+note-G4_eighth+nonote_eighth+nonote_eighth+note-C5_eighth+nonote_eighth+note-D5_eighth+nonote_eighth+nonote_eighth+nonote_eighth+note-A4_eighth+note-D5_eighth+nonote_eighth+nonote_eighth+note-B4_eighth+nonote_eighth+note-A4_eighth+nonote_eighth+note-E5_eighth+note-B4_eighth+nonote_eighth+nonote_eighth+note-A4_eighth+note-A4_eighth+note-C5_eighth+nonote_eighth+nonote_eighth+nonote_eighth+note-B4_eighth+nonote_eighth+note-B4_eighth+note-D5_eighth+nonote_eighth+nonote_eighth+note-A4_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+note-C5_eighth+note-E5_eighth+nonote_eighth+nonote_eighth+note-B4_eighth+nonote_eighth+nonote_quarter+nonote_quarter+nonote_quarter+nonote_quarter+nonote_quarter+nonote_quarter+nonote_quarter+nonote_quarter+nonote_quarter+nonote_quarter+nonote_quarter+nonote_quarter+nonote_quarter+nonote_quarter+nonote_quarter+nonote_eighth+nonote_eighth+note-G4_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+note-A4_eighth+nonote_eighth+nonote_eighth+nonote_eighth+note-C5_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+note-A4_eighth+nonote_eighth+note-B4_eighth+nonote_eighth+note-C5_eighth+note-A4_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+note-G4_eighth+note-A4_eighth+note-B4_eighth+nonote_eighth+note-C5_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+note-C5_eighth+note-C5_eighth+nonote_eighth+note-B4_eighth+nonote_eighth+note-C5_eighth+note-A4_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+note-A4_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+nonote_eighth+note-D5_eighth+note-B4_eighth+note-B4_eighth+nonote_eighth+nonote_eighth+nonote_eighth+note-G4_eighth+nonote_eighth+note-C5_eighth+nonote_eighth+nonote_eighth+nonote_eighth+note-C5_eighth+nonote_eighth+nonote_eighth+nonote_eighth+note-B4_eighth+nonote_eighth+note-C5_eighth+nonote_eighth+nonote_eighth']\n"
     ]
    }
   ],
   "source": [
    "def calculate_SER(S, D, I, N):\n",
    "    \"\"\"\n",
    "    Calculate Symbol Error Rate (SER)\n",
    "    \n",
    "    Parameters:\n",
    "        S (int): Number of substitutions\n",
    "        D (int): Number of deletions\n",
    "        I (int): Number of insertions\n",
    "        N (int): Total number of symbols in the reference sequence\n",
    "        \n",
    "    Returns:\n",
    "        float: Symbol Error Rate\n",
    "    \"\"\"\n",
    "    return (S + D + I) / N if N != 0 else 0.0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # parser = argparse.ArgumentParser(description='Inference single staff image')\n",
    "    # parser.add_argument('filepath', type=str, help='path to staff image')\n",
    "\n",
    "    test_path=\"../data/test/000051650-1_1_1.png\"\n",
    "    cofigpath = \"../src/workspace/config.yaml\"\n",
    "    args = getconfig(cofigpath)\n",
    "    \n",
    "    handler = StaffToScore(args)\n",
    "    predrhythms, predpitchs, predlifts = handler.predict(test_path)\n",
    "\n",
    "    # Example usage:\n",
    "    S = 5  # Number of substitutions\n",
    "    D = 3  # Number of deletions\n",
    "    I = 2  # Number of insertions\n",
    "    N = 100  # Total number of symbols in the reference sequence\n",
    "\n",
    "    SER = calculate_SER(S, D, I, N)\n",
    "    print(\"-- Symbol Error Rate (SER):\", SER)\n",
    "    \n",
    "    mergeds = []\n",
    "    for i in range(len(predrhythms)):\n",
    "        predlift = predlifts[i]\n",
    "        predpitch = predpitchs[i]\n",
    "        predrhythm = predrhythms[i]\n",
    "        \n",
    "        merge = predrhythm[0] + '+'\n",
    "        for j in range(1, len(predrhythm)):\n",
    "            if predrhythm[j] == \"|\":\n",
    "                merge = merge[:-1]+predrhythm[j]\n",
    "            elif \"note\" in predrhythm[j]:\n",
    "                if predlift[j] in (\"lift_##\", \"lift_#\", \"lift_bb\", \"lift_b\", \"lift_N\",):\n",
    "                    lift = predlift[j].split(\"_\")[-1]\n",
    "                merge += predpitch[j]+\"_\"+predrhythm[j].split('note-')[-1]+\"+\"\n",
    "            else:\n",
    "                merge += predrhythm[j]+\"+\"\n",
    "        mergeds.append(merge[:-1])\n",
    "    print(\"-- Result: \", mergeds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
