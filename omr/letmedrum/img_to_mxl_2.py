# # import  aspose.cells 
# # from aspose.cells import Workbook
# # workbook = Workbook("result.png")
# # workbook.save("result.xml")

# import cv2
# import numpy as np
# import music21

# # 1. ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°
# img_path = "result.png"
# img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)

# if img is None:
#     raise FileNotFoundError(f"Image at path '{img_path}' could not be loaded.")

# # 2. ì´ë¯¸ì§€ ì´ì§„í™” (í‘ë°± ë³€í™˜)
# _, binary = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)

# # 3. ìœ¤ê³½ì„  ê²€ì¶œ (ë“œëŸ¼ ê¸°í˜¸ ì°¾ê¸°)
# contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

# # 4. ë“œëŸ¼ ê¸°í˜¸ë³„ ë§¤í•‘ ì •ì˜
# drum_mapping = {
#     "snare": "Snare Drum",
#     "hihat": "Closed Hi-Hat",
#     "bass": "Bass Drum"
# }

# # 5. MusicXML ì•…ë³´ ìƒì„±
# score = music21.stream.Score()
# part = music21.stream.Part()
# part.insert(0, music21.instrument.Percussion())  # ë“œëŸ¼ ì „ìš© ì•…ê¸° ì„¤ì •

# # 6. ê¸°í˜¸ë³„ ìŒí‘œ ë³€í™˜
# for contour in contours:
#     x, y, w, h = cv2.boundingRect(contour)

#     # ê¸°í˜¸ í¬ê¸° ê¸°ë°˜ìœ¼ë¡œ ë“œëŸ¼ ì•…ê¸° íŒë³„ (ì˜ˆì œ ê¸°ì¤€)
#     if h > 50:  # í° ê¸°í˜¸ = ë² ì´ìŠ¤ ë“œëŸ¼
#         drum_type = "bass"
#     elif 30 < h <= 50:  # ì¤‘ê°„ í¬ê¸° = ìŠ¤ë„¤ì–´
#         drum_type = "snare"
#     else:  # ì‘ì€ ê¸°í˜¸ = í•˜ì´í–‡
#         drum_type = "hihat"

#     # ë°•ì ëœë¤ í• ë‹¹ (ê¸°ë³¸ì ìœ¼ë¡œ 8ë¶„ìŒí‘œë¡œ ì„¤ì •)
#     duration = 0.5  

#     # MusicXMLìš© ë“œëŸ¼ ë…¸íŠ¸ ìƒì„±
#     note = music21.note.Unpitched()
#     note.displayName = drum_mapping[drum_type]  # ë“œëŸ¼ ê¸°í˜¸ ì ìš©
#     note.duration = music21.duration.Duration(duration)

#     # ì•…ë³´ì— ì¶”ê°€
#     part.append(note)

# # 7. ì•…ë³´ë¥¼ Scoreì— ì¶”ê°€ í›„ MusicXML ì €ì¥
# score.append(part)
# musicxml_path = "output.musicxml"
# score.write('musicxml', fp=musicxml_path)

# print(f"âœ… ë“œëŸ¼ ì•…ë³´ ë³€í™˜ ì™„ë£Œ! â†’ '{musicxml_path}' ì €ì¥ë¨ ğŸµ")

import cv2
import numpy as np
import pytesseract
from music21 import stream, note

# ğŸµ 1. ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸° & ì „ì²˜ë¦¬
image = cv2.imread("result.png", cv2.IMREAD_GRAYSCALE)
_, thresh = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)
kernel = np.ones((3, 3), np.uint8)
thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)

# ğŸµ 2. OCRë¡œ ë“œëŸ¼ ì•…ë³´ ì¸ì‹
text = pytesseract.image_to_string(thresh, config="--psm 6")
print("ì¸ì‹ëœ ì•…ë³´ ê¸°í˜¸:", text)

# ğŸµ 3. ê¸°í˜¸ â†’ MIDI ë³€í™˜
drum_mapping = {"B": "B4", "S": "C5", "H": "G5"}  # ë² ì´ìŠ¤, ìŠ¤ë„¤ì–´, í•˜ì´í–‡
detected_notes = text.split()
midi_notes = [drum_mapping[n] for n in detected_notes if n in drum_mapping]

# ğŸµ 4. MusicXML ìƒì„±
drum_score = stream.Score()
drum_part = stream.Part()

for midi_note in midi_notes:
    drum_note = note.Note(midi_note)
    drum_note.duration.quarterLength = 1
    drum_part.append(drum_note)

drum_score.append(drum_part)
drum_score.write("musicxml", fp="drum_output.musicxml")

print("ğŸ¼ MusicXML íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤! â†’ drum_output.musicxml")